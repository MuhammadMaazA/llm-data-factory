#!/usr/bin/env python3
"""
Student Model Fine-tuning Script for LLM Data Factory

This script fine-tunes a smaller "Student" model (Phi-3-mini) using the synthetic data
generated by the Teacher model. It uses QLoRA for efficient fine-tuning and includes
comprehensive evaluation and monitoring.
"""

import json
import logging
import os
import random
from pathlib import Path
from typing import Dict, List, Optional

import numpy as np
import torch
from datasets import Dataset, DatasetDict
from dotenv import load_dotenv
from peft import LoraConfig, TaskType, get_peft_model, prepare_model_for_kbit_training
from sklearn.metrics import classification_report, confusion_matrix
from torch.utils.data import DataLoader
from transformers import (
    AutoModelForSequenceClassification,
    AutoTokenizer,
    BitsAndBytesConfig,
    DataCollatorWithPadding,
    EarlyStoppingCallback,
    Trainer,
    TrainingArguments,
    set_seed,
)
from trl import SFTTrainer

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('fine_tuning.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class TicketClassifierTrainer:
    """Class to handle fine-tuning of the student model."""
    
    def __init__(self, config: Optional[Dict] = None):
        """Initialize the trainer with configuration."""
        self.config = config or self._get_default_config()
        self.model_name = self.config['model_name']
        self.output_dir = self.config['output_dir']
        self.categories = self.config['categories']
        self.category_to_id = {cat: idx for idx, cat in enumerate(self.categories)}
        self.id_to_category = {idx: cat for cat, idx in self.category_to_id.items()}
        
        # Set random seeds for reproducibility
        set_seed(self.config['seed'])
        torch.manual_seed(self.config['seed'])
        np.random.seed(self.config['seed'])
        random.seed(self.config['seed'])
        
        # Initialize model and tokenizer
        self.tokenizer = None
        self.model = None
        self.trainer = None
        
    def _get_default_config(self) -> Dict:
        """Get default configuration for training."""
        return {
            'model_name': 'microsoft/phi-3-mini-4k-instruct',
            'output_dir': './final_student_model',
            'categories': ['Urgent Bug', 'Feature Request', 'How-To Question'],
            'max_length': 512,
            'batch_size': 8,
            'gradient_accumulation_steps': 4,
            'learning_rate': 2e-4,
            'num_epochs': 3,
            'warmup_steps': 100,
            'weight_decay': 0.01,
            'logging_steps': 10,
            'eval_steps': 50,
            'save_steps': 100,
            'seed': 42,
            'lora_r': 16,
            'lora_alpha': 32,
            'lora_dropout': 0.1,
            'load_in_4bit': True,
            'bnb_4bit_compute_dtype': torch.float16,
            'bnb_4bit_quant_type': 'nf4',
            'bnb_4bit_use_double_quant': True,
        }
    
    def load_and_preprocess_data(self, data_file: str) -> DatasetDict:
        """Load and preprocess the synthetic data."""
        logger.info(f"Loading data from {data_file}")
        
        with open(data_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        # Convert to dataset format
        dataset_data = []
        for item in data:
            dataset_data.append({
                'text': item['customer_message'],
                'label': self.category_to_id[item['category']],
                'ticket_id': item['ticket_id'],
                'priority': item['priority'],
                'customer_id': item['customer_id']
            })
        
        # Create dataset
        dataset = Dataset.from_list(dataset_data)
        
        # Split into train/validation
        dataset_dict = dataset.train_test_split(test_size=0.2, seed=self.config['seed'])
        
        logger.info(f"Dataset loaded: {len(dataset_dict['train'])} train, {len(dataset_dict['test'])} validation")
        
        # Log class distribution
        train_labels = [item['label'] for item in dataset_dict['train']]
        val_labels = [item['label'] for item in dataset_dict['test']]
        
        logger.info(f"Train class distribution: {np.bincount(train_labels)}")
        logger.info(f"Validation class distribution: {np.bincount(val_labels)}")
        
        return dataset_dict
    
    def setup_model_and_tokenizer(self):
        """Initialize the model and tokenizer with quantization."""
        logger.info(f"Loading model and tokenizer: {self.model_name}")
        
        # Load tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            self.model_name,
            trust_remote_code=True,
            padding_side='right'
        )
        
        # Add padding token if not present
        if self.tokenizer.pad_token is None:
            self.tokenizer.pad_token = self.tokenizer.eos_token
        
        # Configure quantization
        bnb_config = BitsAndBytesConfig(
            load_in_4bit=self.config['load_in_4bit'],
            bnb_4bit_compute_dtype=self.config['bnb_4bit_compute_dtype'],
            bnb_4bit_quant_type=self.config['bnb_4bit_quant_type'],
            bnb_4bit_use_double_quant=self.config['bnb_4bit_use_double_quant'],
        )
        
        # Load model
        self.model = AutoModelForSequenceClassification.from_pretrained(
            self.model_name,
            num_labels=len(self.categories),
            quantization_config=bnb_config,
            device_map='auto',
            trust_remote_code=True,
        )
        
        # Prepare model for k-bit training
        self.model = prepare_model_for_kbit_training(self.model)
        
        # Configure LoRA
        lora_config = LoraConfig(
            r=self.config['lora_r'],
            lora_alpha=self.config['lora_alpha'],
            target_modules=["q_proj", "v_proj", "k_proj", "o_proj", "gate_proj", "up_proj", "down_proj"],
            lora_dropout=self.config['lora_dropout'],
            bias="none",
            task_type=TaskType.SEQ_CLS,
        )
        
        # Apply LoRA
        self.model = get_peft_model(self.model, lora_config)
        self.model.print_trainable_parameters()
        
        logger.info("Model and tokenizer setup completed")
    
    def tokenize_function(self, examples):
        """Tokenize the input texts."""
        return self.tokenizer(
            examples['text'],
            padding='max_length',
            truncation=True,
            max_length=self.config['max_length'],
            return_tensors='pt'
        )
    
    def setup_training(self, train_dataset, val_dataset):
        """Setup the training configuration and trainer."""
        logger.info("Setting up training configuration")
        
        # Training arguments
        training_args = TrainingArguments(
            output_dir=self.output_dir,
            num_train_epochs=self.config['num_epochs'],
            per_device_train_batch_size=self.config['batch_size'],
            per_device_eval_batch_size=self.config['batch_size'],
            gradient_accumulation_steps=self.config['gradient_accumulation_steps'],
            learning_rate=self.config['learning_rate'],
            weight_decay=self.config['weight_decay'],
            warmup_steps=self.config['warmup_steps'],
            logging_steps=self.config['logging_steps'],
            evaluation_strategy="steps",
            eval_steps=self.config['eval_steps'],
            save_strategy="steps",
            save_steps=self.config['save_steps'],
            load_best_model_at_end=True,
            metric_for_best_model="eval_accuracy",
            greater_is_better=True,
            report_to=None,  # Disable wandb for now
            remove_unused_columns=False,
            dataloader_pin_memory=False,
        )
        
        # Data collator
        data_collator = DataCollatorWithPadding(
            tokenizer=self.tokenizer,
            padding=True,
            return_tensors='pt'
        )
        
        # Initialize trainer
        self.trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=val_dataset,
            tokenizer=self.tokenizer,
            data_collator=data_collator,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],
        )
        
        logger.info("Training setup completed")
    
    def train(self):
        """Execute the training process."""
        logger.info("Starting training...")
        
        try:
            # Train the model
            train_result = self.trainer.train()
            
            # Save the final model
            self.trainer.save_model()
            self.tokenizer.save_pretrained(self.output_dir)
            
            # Log training metrics
            logger.info(f"Training completed. Final loss: {train_result.training_loss}")
            
            # Evaluate on validation set
            eval_results = self.trainer.evaluate()
            logger.info(f"Validation results: {eval_results}")
            
            return train_result, eval_results
            
        except Exception as e:
            logger.error(f"Training failed: {e}")
            raise
    
    def evaluate_on_test_data(self, test_data_file: str):
        """Evaluate the trained model on test data."""
        logger.info(f"Evaluating on test data: {test_data_file}")
        
        # Load test data
        with open(test_data_file, 'r', encoding='utf-8') as f:
            test_data = json.load(f)
        
        # Prepare test data
        test_texts = [item['customer_message'] for item in test_data]
        test_labels = [self.category_to_id[item['category']] for item in test_data]
        
        # Tokenize test data
        test_encodings = self.tokenizer(
            test_texts,
            padding=True,
            truncation=True,
            max_length=self.config['max_length'],
            return_tensors='pt'
        )
        
        # Move to device
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        test_encodings = {k: v.to(device) for k, v in test_encodings.items()}
        
        # Make predictions
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(**test_encodings)
            predictions = torch.argmax(outputs.logits, dim=-1).cpu().numpy()
        
        # Calculate metrics
        predicted_categories = [self.id_to_category[pred] for pred in predictions]
        true_categories = [item['category'] for item in test_data]
        
        # Generate classification report
        report = classification_report(
            true_categories,
            predicted_categories,
            target_names=self.categories,
            output_dict=True
        )
        
        # Log results
        logger.info("Test Results:")
        logger.info(f"Accuracy: {report['accuracy']:.4f}")
        for category in self.categories:
            if category in report:
                logger.info(f"{category}: Precision={report[category]['precision']:.4f}, "
                          f"Recall={report[category]['recall']:.4f}, "
                          f"F1={report[category]['f1-score']:.4f}")
        
        # Save detailed results
        results = {
            'accuracy': report['accuracy'],
            'detailed_report': report,
            'predictions': predicted_categories,
            'true_labels': true_categories,
            'test_samples': len(test_data)
        }
        
        results_file = Path(self.output_dir) / 'test_results.json'
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2)
        
        logger.info(f"Detailed results saved to: {results_file}")
        return results


def main():
    """Main function to run the fine-tuning process."""
    try:
        # Setup paths
        script_dir = Path(__file__).parent
        data_dir = script_dir.parent / "data"
        synthetic_data_file = data_dir / "synthetic_data.json"
        test_data_file = data_dir / "test_data.json"
        output_dir = script_dir.parent / "final_student_model"
        
        # Check if synthetic data exists
        if not synthetic_data_file.exists():
            logger.error(f"Synthetic data file not found: {synthetic_data_file}")
            logger.info("Please run the data generation script first: python scripts/01_generate_synthetic_data.py")
            return
        
        # Initialize trainer
        trainer = TicketClassifierTrainer()
        
        # Load and preprocess data
        dataset_dict = trainer.load_and_preprocess_data(str(synthetic_data_file))
        
        # Setup model and tokenizer
        trainer.setup_model_and_tokenizer()
        
        # Tokenize datasets
        tokenized_train = dataset_dict['train'].map(
            trainer.tokenize_function,
            batched=True,
            remove_columns=dataset_dict['train'].column_names
        )
        tokenized_val = dataset_dict['test'].map(
            trainer.tokenize_function,
            batched=True,
            remove_columns=dataset_dict['test'].column_names
        )
        
        # Setup training
        trainer.setup_training(tokenized_train, tokenized_val)
        
        # Train the model
        train_result, eval_results = trainer.train()
        
        # Evaluate on test data if available
        if test_data_file.exists():
            test_results = trainer.evaluate_on_test_data(str(test_data_file))
            logger.info("Test evaluation completed")
        else:
            logger.warning(f"Test data file not found: {test_data_file}")
            logger.info("Skipping test evaluation")
        
        logger.info("Fine-tuning completed successfully!")
        logger.info(f"Model saved to: {output_dir}")
        
    except Exception as e:
        logger.error(f"Fine-tuning failed: {e}")
        raise


if __name__ == "__main__":
    main()
