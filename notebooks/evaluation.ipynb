{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f676f4b",
   "metadata": {},
   "source": [
    "# LLM Data Factory - Model Evaluation\n",
    "\n",
    "This notebook evaluates the performance of our fine-tuned Phi-3-mini student model on customer support ticket classification.\n",
    "\n",
    "## Evaluation Overview\n",
    "\n",
    "We will:\n",
    "1. Load the fine-tuned model\n",
    "2. Load the test dataset\n",
    "3. Generate predictions\n",
    "4. Analyze performance metrics\n",
    "5. Create visualizations\n",
    "6. Compare with baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "547d711c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory to path for imports\n",
    "sys.path.append(str(Path().parent))\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\" Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb248468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test dataset\n",
    "test_data_path = \"../data/test_data.json\"\n",
    "\n",
    "try:\n",
    "    with open(test_data_path, 'r') as f:\n",
    "        test_data = json.load(f)\n",
    "    \n",
    "    print(f\" Loaded {len(test_data)} test samples\")\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    test_df = pd.DataFrame(test_data)\n",
    "    \n",
    "    # Display basic info about the test set\n",
    "    print(\"\\n Test Dataset Overview:\")\n",
    "    print(f\"Total samples: {len(test_df)}\")\n",
    "    print(f\"Categories: {test_df['category'].unique()}\")\n",
    "    print(f\"\\nCategory distribution:\")\n",
    "    print(test_df['category'].value_counts())\n",
    "    \n",
    "    # Display first few examples\n",
    "    print(f\"\\n Sample test tickets:\")\n",
    "    for i, row in test_df.head(3).iterrows():\n",
    "        print(f\"\\n{i+1}. Category: {row['category']}\")\n",
    "        print(f\"   Message: {row['customer_message'][:100]}...\")\n",
    "        \n",
    "except FileNotFoundError:\n",
    "    print(f\"Test data file not found: {test_data_path}\")\n",
    "    print(\"Please ensure you have created the test dataset\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading test data: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43715b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the fine-tuned model\n",
    "try:\n",
    "    from app.inference import load_classifier, predict_ticket_category\n",
    "    \n",
    "    print(\"üîÑ Loading the fine-tuned model...\")\n",
    "    classifier = load_classifier()\n",
    "    \n",
    "    if classifier is not None:\n",
    "        print(\"‚úÖ Model loaded successfully!\")\n",
    "        \n",
    "        # Test with a sample prediction\n",
    "        test_message = \"The app keeps crashing when I try to save my work. This is very urgent!\"\n",
    "        result = predict_ticket_category(classifier, test_message)\n",
    "        \n",
    "        print(f\"\\nüß™ Test prediction:\")\n",
    "        print(f\"Message: {test_message}\")\n",
    "        print(f\"Predicted: {result['predicted_category']}\")\n",
    "        print(f\"Confidence: {result['confidence']:.3f}\")\n",
    "        print(f\"All probabilities: {result['probabilities']}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Failed to load model\")\n",
    "        print(\"This might be because the model hasn't been trained yet.\")\n",
    "        print(\"Please run: python scripts/02_finetune_student_model.py\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error loading model: {e}\")\n",
    "    print(\"Make sure you have trained the model first.\")\n",
    "    classifier = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19211243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for all test samples\n",
    "if classifier is not None and 'test_df' in locals():\n",
    "    print(\"üîÑ Generating predictions for all test samples...\")\n",
    "    \n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    for idx, row in test_df.iterrows():\n",
    "        try:\n",
    "            result = predict_ticket_category(classifier, row['customer_message'])\n",
    "            predictions.append(result['predicted_category'])\n",
    "            confidences.append(result['confidence'])\n",
    "            all_probabilities.append(result['probabilities'])\n",
    "            \n",
    "            if (idx + 1) % 10 == 0:\n",
    "                print(f\"Processed {idx + 1}/{len(test_df)} samples...\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing sample {idx}: {e}\")\n",
    "            predictions.append(\"Unknown\")\n",
    "            confidences.append(0.0)\n",
    "            all_probabilities.append({})\n",
    "    \n",
    "    # Add predictions to dataframe\n",
    "    test_df['predicted_category'] = predictions\n",
    "    test_df['confidence'] = confidences\n",
    "    test_df['probabilities'] = all_probabilities\n",
    "    \n",
    "    print(f\"‚úÖ Generated predictions for {len(test_df)} samples\")\n",
    "    \n",
    "    # Display some example predictions\n",
    "    print(f\"\\nüìù Sample predictions:\")\n",
    "    for i, row in test_df.head(5).iterrows():\n",
    "        correct = \"‚úÖ\" if row['category'] == row['predicted_category'] else \"‚ùå\"\n",
    "        print(f\"{correct} True: {row['category']} | Predicted: {row['predicted_category']} | Confidence: {row['confidence']:.3f}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚è≠Ô∏è Skipping predictions - model not loaded or test data not available\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
